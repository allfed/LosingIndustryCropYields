"""
DATA CLEANING AND PREPROCESSING

Takes "processed/input/crop/" + crop + "_raw.pkl"
            with crop = ["Corn", "Rice", "Soybean", "Wheat"]
as generated by 1_import_data.py as input.

1.) The first part of the code prepares the input data (as generated by 1_import_data) for
    the following GLM analysis. Each set of operations to clean the data was
    defined as a step in the preprocessing:
        a) Step 1: Eliminating all rows below 100 ha.
        b) Step 2: Combining AEZ classes, filling or eliminating missing data.
        c) Step 3: Eliminating outliers.
        d) Clean: Replacing no data values in the continent column.
    The cleaned data sets are saved to file.
    It also calculates the total crop area and saves it to file for use in
    a different script.
    
    Creates the following files:
        1.) "reports/Raw_Column_Area.csv"
        2.) "processed/input/model/" + crop + "_data.gzip"
                with crop = ["Corn", "Rice", "Soybean", "Wheat"]

2.) The second part calculates descriptive statistics for each step (as described above)
    of the data cleaning process to compare the impact each step has on the data.
    The statistics are saved to file.
    
    Creates the following file:
        1.) "reports/Descriptive_Statistics.xlsx"


@author: Jessica MÃ¶rsdorf
jessica@allfed.info
jessi.moersdorf@gmail.com

"""

import os

import src.utilities.params as params  # get file location and varname parameters for
import src.utilities.stat_ut as stat_ut  # get file location and varname parameters for

import pandas as pd
import numpy as np

params.importAll()

crops = ["Corn", "Rice", "Soybean", "Wheat"]

print("Reading crop data and eliminating all rows below 100 ha")

"""
Load raw data and eliminate all rows with an area below 100 ha
"""
data_raw, data_step1 = {}, {}
for crop in crops:
    data_name = "{}_raw".format(crop)
    data_raw[crop] = pd.read_pickle(
        params.cropDataDir + data_name + ".pkl", compression="zip"
    )
    data_raw[crop]["irrigation_rel"] = data_raw[crop]["irrigation_rel"].fillna(0)
    data_raw[crop] = data_raw[crop].replace(
        [data_raw[crop]["n_fertilizer"].min(), -9], np.nan
    )
    data_raw[crop] = data_raw[crop].replace(
        {"continents": 0, "irrigation_tot": -0},
        {"continents": np.nan, "irrigation_tot": 0},
    )
    data_step1[crop] = data_raw[crop].loc[data_raw[crop]["area"] > 100]

print("Done reading crop data and eliminating all rows below 100 ha")


print("Calculating total crop area and saving it to csv")

"""
Calculate area of raw datasets for specified columns to use them in LoI_scenario_data.py
"""


def calculate_area(data, columns):
    dict_area = {}
    for col in columns:
        dict_area[col] = data["area"].loc[data[col].notna()].sum().astype("int")
    return dict_area


# specify columns and apply function for all crops
columns = ["n_fertilizer", "pesticides"]
area_stat = {crop: calculate_area(data_raw[crop], columns) for crop in crops}
# convert dict to dataframe and save to csv
area_col = pd.DataFrame.from_dict(area_stat)
os.makedirs(params.statisticsDir, exist_ok=True)
area_col.to_csv(params.statisticsDir + "Raw_Column_Area.csv")

print("Done calculating total crop area and saving it to csv")


print("Combining AEZ classes, filling or eliminating missing data")

"""
Combine some of the levels of AEZ classes, fill or eliminate missing data
in soil, n+p fertilizer, n_total, pesticides, mechanized and irrigation_rel
"""


# function to fill classes with unreasonable values (for cropland) in soil class
# and combine some of the levels of the thz & mst class to ensure that levels with
# few datapoints don't introduce imbalance into the data
def clean_aez(data):
    data_aez = data.copy()
    # replace 0s, 7s & 8s in the soil class with NaN values so they can be handled with the .fillna method
    data_aez["soil_class"] = data_aez["soil_class"].replace([0, 7, 8], np.nan)
    # fill in the NaN vlaues in the dataset with a forward filling method
    # (replacing NaN with the value in the cell before)
    data_aez = data_aez.fillna(downcast="infer", method="ffill")
    # replace 8,9 & 10 with 7 in the thz class to combine all 3 classes into 1 Temp,cool-Arctic class
    # repalce 2 with 1 and 7 with 6 in the mst class to compile them into 1 joined class each
    data_aez["thz_class"] = data_aez["thz_class"].replace([8, 9, 10], 7)
    data_aez["mst_class"] = data_aez["mst_class"].replace({2: 1, 7: 6})
    return data_aez


# function to fill missing values in the n_fertilizer, p_fertilizer and n_total columns
def clean_fertilizer(data):
    data_fertilizer = data.copy()
    no_data_value = data_fertilizer["n_fertilizer"].min()
    # replace remaining no data values in fertilizer datasets with NaN, then fill them
    data_fertilizer = data_fertilizer.replace(
        {"n_fertilizer": no_data_value}, np.nan
    )
    data_fertilizer = data_fertilizer.fillna(method="ffill")
    # replace NaN values in n_total with sum of the newly filled n_fertilizer and n_manure values
    data_fertilizer.loc[data_fertilizer["n_total"] < 0, "n_total"] = (
        data_fertilizer["n_fertilizer"] + data_fertilizer["n_manure"]
    )
    return data_fertilizer


# for each crop: remove rows with missing data in pesticides and mechanized columns, replace missing values in
# irrigation_rel with 0 and apply the above defined functions
# replace NaN values with -9 so that fillna can be used on the entire dataframe in the next step
data_step2 = {crop: data_step1[crop].replace(np.nan, -9) for crop in crops}
for crop in crops:
    # fill NaN values in soil_class and combine categories in thz & mst class
    data_step2[crop] = clean_aez(data_step2[crop])
    # fill NaN values in n & p fertilizer and n total columns
    data_step2[crop] = clean_fertilizer(data_step2[crop])
    # Eliminate the rows without data in the pesticides and mechanized columns
    data_step2[crop] = data_step2[crop].query("pesticides > -9 and mechanized > -9")
    # replace -9 in continent column with np.nan
    data_step2[crop] = data_step2[crop].replace(-9, np.nan)

print("Done combining AEZ classes, filling or eliminating missing data")


print("Extracting and eliminating outliers")

"""
Calculate and eliminate outliers (values above the 99th/99.9th quantile) from the dataset
and extract the outliers to calculate outlier statistics in a later step
"""


# function to remove all rows from a dataframe where the values of the specified
# columns surpass the specified threshold
def eliminate_outliers(data, factors, thresholds):
    data_outliers = data.loc[
        np.logical_and.reduce([data[factor] < thresholds[factor] for factor in factors])
    ]
    return data_outliers


# function to extract all rows from a dataframe where the values of the specified
# columns surpass the specified threshold and combine the results with the area
# column in one dataframe (area is needed for weighted mean calculations in a later step)
def extract_outliers(data, factors, thresholds):
    outlier = {}
    for factor in factors:
        outlier[factor] = data[factor].loc[data[factor] >= thresholds[factor]]
    outliers = pd.DataFrame(outlier, columns=factors)
    results = pd.concat(
        [outliers, data["area"][data["area"].index.isin(outliers.index)]],
        axis="columns",
    )
    return results


# select the columns of the dataframe where outliers will be calculated

factors = ("Yield", "n_fertilizer", "n_manure", "n_total", "pesticides")

# for each crop: calculate the outlier thresholds and apply the above functions
out_threshold, data_step3, outliers = {}, {}, {}
for crop in crops:
    # combine variables where to calculate the outliers and the 99.9th quantile of each variable into a dictionary
    out_threshold[crop] = dict(zip(factors, data_step2[crop].iloc[:,3:8].quantile(0.999)))
    # replace the value for n_manure with the 99th quantile
    out_threshold[crop]["n_manure"] = data_step2[crop]["n_manure"].quantile(0.99)
    data_step3[crop] = eliminate_outliers(
        data_step2[crop], factors, out_threshold[crop]
    )
    outliers[crop] = extract_outliers(data_step2[crop], factors, out_threshold[crop])

print("Done extracting and eliminating outliers")


print(
    "Replacing no data values in the continent column and saving the clean dataset to file"
)

"""
Replace No Data Values in continent column with corresponding continent value
"""

# Create lists with the continent values for the missing data points
fill_values_Corn = (
    [4] * 11 + [6, 6, 4, 4, 4, 6, 1, 5, 1, 1, 1, 5, 1, 1, 1, 1, 1] + [2] * 39
)
fill_values_Rice = [6] * 12 + [1] * 10 + [2] * 133
fill_values_Soybean = [4] * 3 + [2] * 8
fill_values_Wheat = [4, 6, 5, 5, 5, 5, 5, 1, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2]

# create a dictionary with the NoData index for each crop
NoData_Index = {
    crop: data_step3[crop].loc[data_step3[crop]["continents"].isna()].index
    for crop in crops
}

# store the lists in a dictionary
continents_NoData = {
    "Corn": pd.Series(fill_values_Corn, index=NoData_Index["Corn"]),
    "Rice": pd.Series(fill_values_Rice, index=NoData_Index["Rice"]),
    "Soybean": pd.Series(fill_values_Soybean, index=NoData_Index["Soybean"]),
    "Wheat": pd.Series(fill_values_Wheat, index=NoData_Index["Wheat"]),
}

data_clean = {crop: data_step3[crop].copy() for crop in crops}
for crop in crops:
    # set the cells where continent==0 to the values stored in the continents_NoData dict
    data_clean[crop]["continents"] = data_clean[crop]["continents"].fillna(
        continents_NoData[crop], downcast="infer"
    )
    # save the clean dataset to csv
    os.makedirs(params.modelDataDir, exist_ok=True)

    data_clean[crop].to_csv(
        params.modelDataDir + crop + "_data.gzip", compression="gzip"
    )

print(
    "Done replacing no data values in the continent column and saving the clean dataset to file"
)


print("Calculating descriptive statistics and saving them to file")

"""
Descriptive Statistics for each step and each crop
"""

# specify the overview metrics
metrics = ["Total_Area(ha)", "Number_Rows"]
#specify the steps for which the statistics will be calculated
steps = ["raw", "step1", "step2", "clean", "outliers"]
#specify the categorical factors, as the mean will be calculated differently
cat = ("mechanized", "thz_class", "mst_class", "soil_class", "continents")
#specify the columns for which the statistics will be calculated
columns_stat = ("Yield", "n_fertilizer", "n_manure", "n_total", "pesticides", "irrigation_tot", "irrigation_rel",
                "mechanized", "thz_class", "mst_class", "soil_class", "continents")

#compile the data set for each step and the columns specified above in a dictionary
data = {
    "raw": [data_raw, columns_stat],
    "step1": [data_step1, columns_stat],
    "step2": [data_step2, columns_stat],
    "clean": [data_clean, columns_stat],
    "outliers": [outliers, factors],
}

#calculate two overview statistics (metrics) for each crop and each step
#the overview metrics do not depend on the column
overview_stats, df_list = {}, []
for crop in crops:
    overview_stats[crop] = [], []
    for step in steps:
        overview_stats[crop][0].append(data[step][0][crop]["area"].sum())
        overview_stats[crop][1].append(len(data[step][0][crop]))
    df = pd.DataFrame(overview_stats[crop], index=metrics, columns=steps).astype("int")
    df.columns = pd.MultiIndex.from_product([[crop], df.columns])
    df_list.append(df)
result = pd.concat(df_list, axis=1).transpose()


#calculate descriptive statistics (Weighted mean/mode, minimum, maximum, crop area,
#outlier threshold, number of outliers, the number of no data values and the number of zeros)
#for each crop, step and column
descriptive_stats, desc_stats = {}, {}
for crop in crops:
    descriptive_stats[crop] = {}
    df_list = []
    for step in steps:
        descriptive_stats[crop][step] = pd.DataFrame(
            data[step][0][crop].loc[:, data[step][1]].max(), columns=["2_Maximum"]
        )
        descriptive_stats[crop][step]["1_Minimum"] = (
            data[step][0][crop].loc[:, data[step][1]].min()
        )
        descriptive_stats[crop][step]["0_Weighted_Mean_Mode"] = (
            data[step][0][crop]
            .loc[:, data[step][1]]
            .apply(
                lambda x: stat_ut.weighted_average(
                    x, weights=data[step][0][crop]["area"], dropna=True
                )
            )
        )
        if step == "outliers":
            descriptive_stats[crop][step]["3_Outlier_threshold"] = out_threshold[
                crop
            ].values()
            descriptive_stats[crop][step].loc[data[step][1], "4_Number_Outliers"] = (
                data[step][0][crop].loc[:, data[step][1]].notna().sum()
            )
        else:
            descriptive_stats[crop][step]["5_NaN_count"] = (
                data[step][0][crop].loc[:, data[step][1]].isna().sum()
            )
            descriptive_stats[crop][step]["6_0_count"] = (
                data[step][0][crop].loc[:, data[step][1]] == 0
            ).sum()
            descriptive_stats[crop][step].loc[cat, "0_Weighted_Mean_Mode"] = (
                data[step][0][crop]
                .loc[:, cat]
                .apply(
                    lambda x: stat_ut.weighted_mode(
                        x, weights=data[step][0][crop]["area"], dropna=True
                    )
                )
            )
        descriptive_stats[crop][step].columns = pd.MultiIndex.from_product(
            [descriptive_stats[crop][step].columns, [step]]
        )
        df_list.append(descriptive_stats[crop][step])
    desc_stats[crop] = pd.concat(df_list, axis=1).sort_index(
        level=0, axis=1, sort_remaining=False
    )


# Create a Pandas Excel writer using XlsxWriter as the engine.
with pd.ExcelWriter(params.statisticsDir + "Descriptive_Statistics.xlsx") as writer:
    # Write each dataframe to a different worksheet.
    result.to_excel(writer, sheet_name="Overview")
    desc_stats["Corn"].to_excel(writer, sheet_name="Corn")
    desc_stats["Rice"].to_excel(writer, sheet_name="Rice")
    desc_stats["Soybean"].to_excel(writer, sheet_name="Soybean")
    desc_stats["Wheat"].to_excel(writer, sheet_name="Wheat")

print("Done calculating descriptive statistics and saving them to file")    
